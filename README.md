# Chinese Checker

Analyze Chinese text from input files to gauge comprehension based on your known words.

## Acknowledgments

This project is based on [Destaq/chinese-comprehension](https://github.com/Destaq/chinese-comprehension) as the starting point.

## Features
- Batch text file analysis with comprehension percentage
- pkuseg word segmentation (~97% accuracy)
- Automatic proper noun detection (excludes names/places)
- Unknown words listed with pinyin, frequency, and definitions
- Organize known/unknown words across multiple `.txt` files

## Requirements
Python 3.9+ and dependencies in `requirements.txt` (pkuseg, spaCy, pypinyin)

## Installation

```bash
git clone https://github.com/chelsea6502/chinese-checker.git
cd chinese-checker
pip install -r requirements.txt
```

Models (pkuseg + spaCy zh_core_web_sm) download automatically on first run.

## Usage

1. Place Chinese text files (`.txt`) in the `input/` directory
2. Run: `python script.py`

The script will process all `.txt` files in the `input/` directory and generate a comprehension report for each file.

### Known Words Directory
Create `.txt` files in the `known/` directory with one word per line. You can organize words across multiple files:

**known/hsk1.txt:**
```
æ˜¯
ä½ å¥½
å†è§
```

**known/hsk2.txt:**
```
æœ‰
äº”
```

### Unknown Words Directory (Optional)
Create `.txt` files in the `unknown/` directory to list compound words that shouldn't count as known even if individual characters are known:

**unknown/compounds.txt:**
```
å¥½åƒ	# hÇo chÄ«
é“ç†	# dÃ o lÇ
è¡Œè€…	# xÃ­ng zhÄ›
```

Entries in `known/` files take priority over `unknown/` files.

## Example Output

```
============================================================
File: story.txt
============================================================

Word Count: 1523
Total Unique Words: 487
Comprehension: 92.3% - ğŸŸ¢ Optimal (i+1)
Unique Unknown Words: 23

=== Unknown Words (by frequency) ===
é“ (dÃ o) : 15 - way, path, principle
è¡Œè€… (xÃ­ng zhÄ›) : 8 - traveler, pilgrim
è£ (lÇ) : 6 - inside, interior
èˆ‡ (yÇ”) : 5 - and, with, to give
...
```

## Technical Details

**Segmentation Strategy:**
1. Match against all `.txt` files in `known/` directory (dynamic programming)
2. Match against all `.txt` files in `unknown/` directory
3. Fallback to pkuseg for remaining text

**Proper Noun Detection:** spaCy NER excludes PERSON, GPE, ORG, FAC, LOC entities from calculations.

## License

MIT
